{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "import jieba\n",
    "from collections import Counter\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open (\"../data/diendata.json\") as f:\n",
    "    ipeendata=json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipeendata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "for dien in ipeendata:\n",
    "    if dien['Ncomment']!=0:\n",
    "        \n",
    "        try:\n",
    "            comments=json.load(open(\"../data/diencomments/\"+str(dien['id'])+\".json\"))\n",
    "            n+=1\n",
    "            if n%1000==0:\n",
    "#                 print(\"已讀取{}筆資料\".format(n))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            comments=[]\n",
    "    else:\n",
    "        comments=[]\n",
    "    dien[\"comments\"]=comments\n",
    "print(\"讀取完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipeendata=[dien for dien in ipeendata if dien['Ncomment'] >0 and dien['address']!=\"\" and dien['status']=='正常營業' and dien['comments']!=[]]\n",
    "print(len(ipeendata))\n",
    "# ipeendata[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.set_dictionary('D:/dict/jieba_dict.txt.big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#停止慈字典\n",
    "stopwordset = set()\n",
    "with open('D:/dict/stopwords.txt', 'r') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "        \n",
    "#自製餐廳相關字字典pinlist\n",
    "with open(\"D:/dict/FoodMoodDict.csv\") as f:\n",
    "    mydict=f.read()\n",
    "#linewords pindict每個字的評分dict\n",
    "linewords=[{myword:float(line.split(\",\")[0]) for myword in line.split(\",\")[1:]}\\\n",
    "           for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\"]\n",
    "pindict={}\n",
    "for word in linewords:\n",
    "    pindict.update(word)\n",
    "pinlist=list(pindict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipeendata[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各種資料list\n",
    "dienlist = [dien[\"name\"] for dien in ipeendata]\n",
    "bigstylelist = [dien[\"bigstyle\"] for dien in ipeendata]\n",
    "smallstylelist = [dien[\"smallstyle\"] for dien in ipeendata]\n",
    "\n",
    "\n",
    "\n",
    "#將以上字典都加入斷詞行列\n",
    "for i in dienlist:\n",
    "    jieba.add_word(i)\n",
    "for i in bigstylelist:\n",
    "    jieba.add_word(i)\n",
    "\n",
    "for i in smallstylelist:\n",
    "    jieba.add_word(i)\n",
    "for i in pinlist:\n",
    "    if i !=\"\":\n",
    "        jieba.add_word(i)\n",
    "        \n",
    "latlist = [dien['lat'] for dien in ipeendata]\n",
    "lnglist = [dien['lng'] for dien in ipeendata]\n",
    "Ncommentlist = [i[\"Ncomment\"] for i in ipeendata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diencommentlist=[[j[\"content\"] for j in i[\"comments\"]] for i in ipeendata]\n",
    "diencommentlist[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dienmessagelist=[[''.join(j[\"message\"]) for j in i[\"comments\"] if j[\"message\"]!=None and j[\"message\"]!='null'] for i in ipeendata]\n",
    "dienmessagelist[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#回覆數量\n",
    "Nmessagelist=[len(dienmessage) for dienmessage in dienmessagelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#全部回覆+全部評論\n",
    "dienallpinlist=[diencomment+dienmessage for diencomment,dienmessage in zip(diencommentlist,dienmessagelist)]\n",
    "# dienallpinlist[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把所有回覆合併\n",
    "messagecombinlist=[\" \".join([\"\".join(meg) for meg in megs if meg!=None and meg!='null'and meg!='']) for megs in dienmessagelist]\n",
    "# messagecombinlist[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把所有評論合併\n",
    "commentcombinelist = [\" \".join([j[\"content\"] for j in i[\"comments\"]]) for i in ipeendata]\n",
    "# commentcombinelist[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#合併評論+回覆\n",
    "pincombinelist=[comment+\" \"+message for comment,message in zip(commentcombinelist,messagecombinlist)]\n",
    "# pincombinelist[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清一下記憶體\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st=time.time()\n",
    "#取得各店家的斷完詞評論pincutlist\n",
    "pincutlist = []\n",
    "cutcount=0\n",
    "for pincombine in pincombinelist:\n",
    "    if pincombine!=\"\":\n",
    "        cutcount+=1\n",
    "        if cutcount%200==0:\n",
    "            print(\"已切\"+str(cutcount)+\"篇文章的詞\")\n",
    "        words = jieba.cut(pincombine, cut_all=False)\n",
    "        pincut=\" \".join([word for word in words if word not in stopwordset and '\\u4e00' <= word and word <= '\\u9fff'])\n",
    "        pincutlist.append(pincut)\n",
    "    else:\n",
    "        pincutlist.append(\"\")\n",
    "et=time.time()\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#清一下記憶體\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myapi import TextMining\n",
    "TM=TextMining.TextMining(pincutlist)\n",
    "wordCountlist=TM.getWordCountList()\n",
    "TF_IDFlist=TM.getTFIDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #所有店家的用詞加總前三百wordCountlist300\n",
    "# wordCountlist=[Counter(pincut.split(\" \")).most_common(300) for pincut in pincutlist]\n",
    "\n",
    "# st=time.time()\n",
    "# #TF計算 (TF=這個字出現的次數/這篇文章的總字數)\n",
    "# #(sum(dict(wordCount).values())=>一篇所有字的字數  wordkv[1]>>該文字字數  wordkv[0]>>該文字)\n",
    "# #TFList每篇文章的詞 的詞頻\n",
    "# # TFList=[[((wordkv[0],wordkv[1]/sum(dict(wordCount).values()))) for wordkv in wordCount] for wordCount in wordCountlist]\n",
    "# n=0\n",
    "# TFList=[]\n",
    "# for wordCount in wordCountlist:\n",
    "#     n+=1\n",
    "#     if n%1000==0:\n",
    "#         print(n)\n",
    "#     TF={}\n",
    "#     allwords=sum(dict(wordCount).values())\n",
    "#     for wordkv in wordCount:\n",
    "#         TF[wordkv[0]]=(wordkv[1]/allwords)\n",
    "#     TFList.append(TF)\n",
    "    \n",
    "\n",
    "# #全文章共用了幾個詞(set可以去除重複，可迭代)\n",
    "# wordlist=[]\n",
    "# for wordCount in wordCountlist:\n",
    "#     for word in wordCount:\n",
    "#         wordlist.append(word[0])\n",
    "# wordlist=set(wordlist)\n",
    "\n",
    "# #nDien所有的文章(店家)數\n",
    "# ndien=len(dienlist)\n",
    "\n",
    "# et=time.time()\n",
    "# print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#清一下記憶體\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #計算各字出現次數\n",
    "# st=time.time()\n",
    "# wordappear={}\n",
    "# k=0\n",
    "# for wordCount in wordCountlist:\n",
    "#     k+=1\n",
    "#     if k%3000==0:\n",
    "#         print(k)\n",
    "#     for word in dict(wordCount).keys():\n",
    "#         if word in wordappear:\n",
    "#             wordappear[word]+=1\n",
    "#         else:\n",
    "#             wordappear[word]=1\n",
    "            \n",
    "# et=time.time()\n",
    "# print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del wordappear[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # #wordappear計算每個字出現於 (幾篇) 文章\n",
    "# st=time.time()\n",
    "# # wordappear={}\n",
    "# # appearcount=0\n",
    "# # for word in wordlist:\n",
    "# #     appearcount+=1\n",
    "# #     if appearcount%1000==0:\n",
    "# #         print(\"以計算\"+str(appearcount)+\"個文字的出現篇數\")\n",
    "# #     n=0\n",
    "# #     for pincut in pincutlist:\n",
    "# #         if word in pincut:\n",
    "# #             n+=1\n",
    "# #     wordappear[word]=n\n",
    "# #IDF(逆向檔案頻率)=某詞  所有文章數/在幾篇文章出現 開log10 >>次方數為所\n",
    "# IDFlist={word:math.log(ndien/wordappear[word],10) for word in wordappear}\n",
    "\n",
    "\n",
    "    \n",
    "# et=time.time()\n",
    "# print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(IDFlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFList[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #dienTF每家店的全字TF值 wordTF每個詞的TF   wordTF[0]詞 wordTF[1]詞的TF值  IDFlist[wordTF[0]]詞的IDF值\n",
    "# # TF_IDFlist=[Counter({wordTF[0]:wordTF[1]*IDFlist[wordTF[0]]for wordTF in dienTF})for dienTF in TFList]\n",
    "# # for name,TFIDF in zip(dienlist,TF_IDFlist):\n",
    "# #     if name in TFIDF:\n",
    "# #         del TFIDF[name]\n",
    "# n=0\n",
    "# TF_IDFlist=[]\n",
    "# for dienTF in TFList:\n",
    "#     n+=1\n",
    "#     if n%3000==0:\n",
    "#         print(n)\n",
    "#     x=Counter()\n",
    "#     for wordTF in dienTF:\n",
    "#         x.update({wordTF:dienTF[wordTF]})\n",
    "#     TF_IDFlist.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name,TFIDF in zip(dienlist,TF_IDFlist):\n",
    "    if name in TFIDF:\n",
    "        del TFIDF[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# st=time.time()\n",
    "# pinCountMaxper5list = []\n",
    "# countN=0\n",
    "# for dienallpin in dienallpinlist:\n",
    "#     dienWordcount={}\n",
    "#     for allpin in  dienallpin:\n",
    "#         countN+=1\n",
    "#         if countN%100==0:\n",
    "#             print(\"已算完\"+str(countN)+\"篇情緒字\")\n",
    "#         for pinword in pinlist:\n",
    "#             if len(re.findall(pinword,allpin))>0:\n",
    "#                 if len(re.findall(pinword,allpin))>5:\n",
    "#                     npinword=5\n",
    "#                 else:\n",
    "#                     npinword=len(re.findall(pinword,allpin))\n",
    "#                 if pinword not in dienWordcount:\n",
    "#                     dienWordcount[pinword]=0\n",
    "#                 dienWordcount[pinword]+=npinword\n",
    "#     pinCountMaxper5list.append(dienWordcount)\n",
    "# ed=time.time()\n",
    "# print(ed-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st=time.time()\n",
    "pinCountMaxper5list = []\n",
    "countN=0\n",
    "for dienallpin in dienallpinlist:\n",
    "    dienWordcount={}\n",
    "    for allpin in  dienallpin:\n",
    "        countN+=1\n",
    "        if countN%100==0:\n",
    "            print(\"已算完\"+str(countN)+\"篇情緒字\")\n",
    "        for pinword in pinlist:\n",
    "            nword=len(re.findall(pinword,allpin))\n",
    "            if nword>0:\n",
    "                if nword>5:\n",
    "                    npinword=5\n",
    "                else:\n",
    "                    npinword=nword\n",
    "                if pinword not in dienWordcount:\n",
    "                    dienWordcount[pinword]=0\n",
    "                dienWordcount[pinword]+=npinword\n",
    "    pinCountMaxper5list.append(dienWordcount)\n",
    "ed=time.time()\n",
    "print(ed-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Npartpin=[int(Nmessage/6)+Ncomment for Nmessage,Ncomment in zip(Nmessagelist,Ncommentlist)]\n",
    "\n",
    "\n",
    "#大致計算每家店的分數dienscorelist\n",
    "dienscorelist=[]\n",
    "for pinCount,N in zip(pinCountMaxper5list,Npartpin):\n",
    "    dienscore=0\n",
    "    for pin in pinCount:\n",
    "        dienscore+=pinCount[pin]*pindict[pin]/N\n",
    "    dienscorelist.append(dienscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synonyms=[{word:line.split(\",\")[1] for word in line.split(\",\")[1:]} for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\"]\n",
    "\n",
    "pinsynonymsdict={}\n",
    "for synonym in synonyms:\n",
    "    pinsynonymsdict.update(synonym)\n",
    "del pinsynonymsdict[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurescores=[]\n",
    "\n",
    "#將評價詞加總及評論次數做iterate\n",
    "for pinCountMaxper5,N in zip(pinCountMaxper5list,Npartpin):\n",
    "    dienfeaturescore={}\n",
    "    \n",
    "    # 評價詞出現次數/評論次數 做為分數，其中否字開頭給負分\n",
    "    for pin in pinCountMaxper5:\n",
    "        if pin !=\"\":\n",
    "            if pinsynonymsdict[pin][0]==\"否\":\n",
    "                if pinsynonymsdict[pin][1:] not in dienfeaturescore:\n",
    "                    dienfeaturescore[pinsynonymsdict[pin][1:]]=0\n",
    "                dienfeaturescore[pinsynonymsdict[pin][1:]]-=round(pinCountMaxper5[pin]/N,2)*1\n",
    "            else:\n",
    "                if pinsynonymsdict[pin] not in dienfeaturescore:\n",
    "                    dienfeaturescore[pinsynonymsdict[pin]]=0\n",
    "                dienfeaturescore[pinsynonymsdict[pin]]+=round(pinCountMaxper5[pin]/N,2)\n",
    "    if len(dienfeaturescore)==0:\n",
    "        dienfeaturescore[\"無評\"]=1\n",
    "    featurescores.append(dienfeaturescore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BigAnalyzeTable=[]\n",
    "for name,bigstyle,smallstyle,Ncomment,contentcut,wordCount,TFIDF,pinCountMax5,score,featurescore,introduction,lat,lng in zip(dienlist,bigstylelist,smallstylelist,Npartpin,pincutlist,wordCountlist,TF_IDFlist,pinCountMaxper5list,dienscorelist,featurescores,latlist,lnglist):\n",
    "    dien={}\n",
    "    dien['name']=name\n",
    "    dien['bigstyle']=bigstyle\n",
    "    dien['smallstyle']=smallstyle\n",
    "    dien['Ncomment']=Ncomment\n",
    "    dien['contentcut']=contentcut\n",
    "    dien['wordCount']=wordCount\n",
    "    dien['TF_IDF']=TFIDF\n",
    "    dien['pinCountMaxper5']=pinCountMax5\n",
    "    dien['score']=score\n",
    "    dien['featurescores']=featurescore\n",
    "    dien['tags']=[tag[0] for tag in Counter(TFIDF).most_common(5)]\n",
    "    dien['lat']=lat\n",
    "    dien['lng']=lng\n",
    "    \n",
    "    \n",
    "    BigAnalyzeTable.append(dien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#算出每個評論的評論數N時的 最大值b 最小值g for正規化\n",
    "\n",
    "\n",
    "#allpin=評論詞list\n",
    "allpin=set([line.split(\",\")[1] for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\" and line.split(\",\")[1][0]!=\"否\"])\n",
    "standard={}\n",
    "\n",
    "#standard為正規化所需用的值\n",
    "for pin in allpin:\n",
    "    for rang in [(0,5),(5,10),(10,15),(15,100)]:\n",
    "        get={}\n",
    "        values=[dien['featurescores'][pin] for dien in BigAnalyzeTable if pin in dien['featurescores'] and dien[\"Ncomment\"]>rang[0] and dien[\"Ncomment\"]<=rang[1]]\n",
    "        b=0\n",
    "        g=0\n",
    "        for value in values:\n",
    "            if value <b:\n",
    "                b=round(value,1)\n",
    "            if value >g:\n",
    "                g=round(value,1)\n",
    "        get[pin+str(rang[0])]=((g+b)/2,g-(g+b)/2)\n",
    "        standard.update(get)\n",
    "        print(pin+\"+\"+str(rang[0])+\"\\t\"+str(g)+\"\\t\"+str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#進行正規化的處理\n",
    "for dien in BigAnalyzeTable:\n",
    "    N=dien['Ncomment']\n",
    "    for feature in dien['featurescores']:\n",
    "        if feature !=\"無評\":\n",
    "            if N<6:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(0)][1],2)\n",
    "            elif N<11 and N>=6:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(5)][1],2)\n",
    "            elif N<16 and N>=11:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(10)][1],2)\n",
    "            else:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(15)][1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allpin=[line.split(\",\")[1] for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\" and line.split(\",\")[1][0]!=\"否\"]\n",
    "standard={}\n",
    "\n",
    "for pin in allpin:\n",
    "    for rang in [(0,5),(5,10),(10,15),(15,100)]:\n",
    "#         get={}\n",
    "        values=[dien['featurescores'][pin] for dien in BigAnalyzeTable if pin in dien['featurescores'] and dien[\"Ncomment\"]>rang[0] and dien[\"Ncomment\"]<=rang[1]]\n",
    "        b=0\n",
    "        g=0\n",
    "        for value in values:\n",
    "            if value <b:\n",
    "                b=round(value,1)\n",
    "            if value >g:\n",
    "                g=round(value,1)\n",
    "#         get[pin+str(rang[0])]=((g+b)/2,g-(g+b)/2)\n",
    "#         standard.update(get)\n",
    "        print(pin+\"+\"+str(rang[0])+\"\\t\"+str(g)+\"\\t\"+str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipin=[('食物美味','食物不好吃',\"非常好吃\",'非常不好吃'),('划算','價格較高昂',\"非常便宜\",'非常貴')\n",
    "       ,('環境好','環境比較不好',\"環境超棒\",'環境很差'),('服務好','服務較差',\"服務一級棒\",'服務很差')\n",
    "       ,('其他正面情緒','評論有些負面情緒詞',\"網路評論正面情緒非常多\",'網路評論負面情緒很多')]\n",
    "moods=[mood[0] for mood in pipin]\n",
    "for dien in BigAnalyzeTable:\n",
    "    newtag=[]\n",
    "    for feature in dien[\"featurescores\"]:\n",
    "        if feature in moods:\n",
    "            if dien[\"featurescores\"][feature]>1:\n",
    "                for pinpare in pipin:\n",
    "                    if feature==pinpare[0]:\n",
    "                        newtag.append(pinpare[2])\n",
    "            elif dien[\"featurescores\"][feature]>0.4:\n",
    "                newtag.append(feature)\n",
    "            elif dien[\"featurescores\"][feature]<-0.5:\n",
    "                for pinpare in pipin:\n",
    "                    if feature==pinpare[0]:\n",
    "                        newtag.append(pinpare[3])\n",
    "            elif dien[\"featurescores\"][feature]<0.0:\n",
    "                for pinpare in pipin:\n",
    "                    if feature==pinpare[0]:\n",
    "                        newtag.append(pinpare[1])\n",
    "        else:\n",
    "            if dien[\"featurescores\"][feature]>0.7:\n",
    "                newtag.append(feature)\n",
    "                    \n",
    "                    \n",
    "#用set去除重複標籤\n",
    "    dien['tags']=list(set(dien['tags']+newtag))\n",
    "    print(dien['name'])\n",
    "#     print(newtag)\n",
    "    dien['tags'].append(dien['bigstyle'])\n",
    "    print(dien['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in BigAnalyzeTable:\n",
    "    if i['score']>30 and i['Ncomment']>10:\n",
    "        print(i['name']+' '+str(i['score']))\n",
    "#         print(i['tags'])\n",
    "        print(i['featurescores'])\n",
    "        print('\\n')\n",
    "gooddien=[i for i in BigAnalyzeTable if i['score']>30 and i['Ncomment']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/bigtable.json','w') as f:\n",
    "    json.dump(BigAnalyzeTable,f)\n",
    "with open('../data/GoodDien.json','w') as f:\n",
    "    json.dump(gooddien,f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(BigAnalyzeTable[3]['lng'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試做word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/bigtable.json') as f:\n",
    "    BigAnalyzeTable=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contentcutcombine=\" \".join([i['contentcut'] for i in BigAnalyzeTable])\n",
    "with open('../data/contentcutcombine.txt','w',encoding=\"utf-8\") as w:\n",
    "    w.write(contentcutcombine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus('../data/contentcutcombine.txt')\n",
    "model = word2vec.Word2Vec(sentences, size=250,window=6, min_count=4, workers=4,sg=1)\n",
    "\n",
    "# Save our model.\n",
    "\n",
    "model.save(\"../data/W2Vmodel/med250.model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = models.Word2Vec.load('../data/W2Vmodel/med250.model.bin')\n",
    "\n",
    "print(\"提供 3 種測試模式\\n\")\n",
    "print(\"輸入一個詞，則去尋找前一百個該詞的相似詞\")\n",
    "print(\"輸入兩個詞，則去計算兩個詞的餘弦相似度\")\n",
    "print(\"輸入三個詞，進行類比推理\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        query = input()\n",
    "        q_list = query.split()\n",
    "\n",
    "        if len(q_list) == 1:\n",
    "            print(\"相似詞前 30 排序\")\n",
    "            res = model.most_similar(q_list[0],topn = 30)\n",
    "            for item in res:\n",
    "                print(item[0]+\",\"+str(item[1]))\n",
    "\n",
    "        elif len(q_list) == 2:\n",
    "            print(\"計算 Cosine 相似度\")\n",
    "            res = model.similarity(q_list[0],q_list[1])\n",
    "            print(res)\n",
    "        else:\n",
    "            print(\"%s之於%s，如%s之於\" % (q_list[0],q_list[2],q_list[1]))\n",
    "            res = model.most_similar([q_list[0],q_list[1]], [q_list[2]], topn= 20)\n",
    "            for item in res:\n",
    "                print(item[0]+\",\"+str(item[1]))\n",
    "        print(\"----------------------------\")\n",
    "    except Exception as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../data/bigtable.json') as f:\n",
    "#     BigAnalyzeTable=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pincutlist=[dien[\"contentcut\"] for dien in BigAnalyzeTable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from myapi import TextMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from myapi import TextMining\n",
    "# TM=TextMining.TextMining(pincutlist)\n",
    "# wordCountlist=TM.getWordCountList()\n",
    "# TF_IDFlist=TM.getTFIDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
